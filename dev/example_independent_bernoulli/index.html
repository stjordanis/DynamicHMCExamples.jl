<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Estimate Bernoulli draws probabilility ¬∑ DynamicHMCExamples.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>DynamicHMCExamples.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Overview</a></li><li class="current"><a class="toctext" href>Estimate Bernoulli draws probabilility</a><ul class="internal"></ul></li><li><a class="toctext" href="../example_linear_regression/">Linear regression</a></li><li><a class="toctext" href="../example_logistic_regression/">Logistic regression</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Estimate Bernoulli draws probabilility</a></li></ul><a class="edit-page" href="https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_independent_bernoulli.jl"><span class="fa">ÔÇõ</span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Estimate Bernoulli draws probabilility</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Estimate-Bernoulli-draws-probabilility-1" href="#Estimate-Bernoulli-draws-probabilility-1">Estimate Bernoulli draws probabilility</a></h1><p>We estimate a simple model of <span>$n$</span> independent Bernoulli draws, with probability <span>$Œ±$</span>. First, we load the packages we use.</p><pre><code class="language-julia">using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics
using MCMCDiagnostics
using Parameters, Statistics, Random
import ForwardDiff              # use for AD</code></pre><p>Then define a structure to hold the data. For this model, the number of draws equal to <code>1</code> is a sufficient statistic.</p><pre><code class="language-julia">&quot;&quot;&quot;
Toy problem using a Bernoulli distribution.

We model `n` independent draws from a ``Bernoulli(Œ±)`` distribution.
&quot;&quot;&quot;
struct BernoulliProblem
    &quot;Total number of draws in the data.&quot;
    n::Int
    &quot;Number of draws `==1` in the data&quot;
    s::Int
end</code></pre><pre><code class="language-none">Main.ex-example_independent_bernoulli.BernoulliProblem</code></pre><p>Then make the type callable with the parameters <em>as a single argument</em>.  We use decomposition in the arguments, but it could be done inside the function, too.</p><pre><code class="language-julia">function (problem::BernoulliProblem)(Œ∏)
    @unpack Œ± = Œ∏               # extract the parameters
    @unpack n, s = problem      # extract the data
    # log likelihood: the constant log(combinations(n, s)) term
    # has been dropped since it is irrelevant to sampling.
    s * log(Œ±) + (n-s) * log(1-Œ±)
end</code></pre><p>We should test this, also, this would be a good place to benchmark and optimize more complicated problems.</p><pre><code class="language-julia">p = BernoulliProblem(20, 10)
p((Œ± = 0.5, ))</code></pre><pre><code class="language-none">-13.862943611198906</code></pre><p>Recall that we need to</p><ol><li><p>transform from <span>$‚Ñù$</span> to the valid parameter domain <code>(0,1)</code> for more efficient sampling, and</p></li><li><p>calculate the derivatives for this transformed mapping.</p></li></ol><p>The helper packages <code>TransformVariables</code> and <code>LogDensityProblems</code> take care of this. We use a flat prior (the default, omitted)</p><pre><code class="language-julia">t = as((Œ± = asùïÄ,))
P = TransformedLogDensity(t, p)
‚àáP = ADgradient(:ForwardDiff, P);</code></pre><pre><code class="language-none">ForwardDiff AD wrapper for TransformedLogDensity of dimension 1, w/ chunk size 1</code></pre><p>Finally, we sample from the posterior. <code>chain</code> holds the chain (positions and diagnostic information), while the second returned value is the tuned sampler which would allow continuation of sampling.</p><pre><code class="language-julia">results = mcmc_with_warmup(Random.GLOBAL_RNG, ‚àáP, 1000)</code></pre><pre><code class="language-none">(chain = Array{Float64,1}[[-0.3125508450359048], [0.44976790986475934], [-0.06240261670871372], [-0.3053745082384359], [0.21808880929120833], [0.2115490316523536], [0.756388892706644], [0.8114763273964696], [0.6694954840176217], [-0.13542678816185316]  ‚Ä¶  [-0.6029660943976114], [-0.5687956235663616], [-0.15908333326808688], [0.13600595556483464], [0.06401188662520216], [-0.045021595498745653], [-0.06830678370983763], [0.029614295367681967], [0.14705480262928572], [-0.39672451973145706]], tree_statistics = DynamicHMC.TreeStatisticsNUTS[DynamicHMC.TreeStatisticsNUTS(-16.565614905151236, 1, turning at positions 1:2, 0.895455602391498, 3, DynamicHMC.Directions(0xed564946)), DynamicHMC.TreeStatisticsNUTS(-17.543436900047862, 1, turning at positions -2:-3, 0.8153798378177629, 3, DynamicHMC.Directions(0x97d57258)), DynamicHMC.TreeStatisticsNUTS(-16.34136544889215, 1, turning at positions 2:3, 0.9558339822173295, 3, DynamicHMC.Directions(0x20f8e65b)), DynamicHMC.TreeStatisticsNUTS(-15.5174941475032, 2, turning at positions -3:0, 0.9753907698796063, 3, DynamicHMC.Directions(0xb94c16dc)), DynamicHMC.TreeStatisticsNUTS(-16.306803193336386, 1, turning at positions -2:-3, 0.9256983102627107, 3, DynamicHMC.Directions(0xacee3744)), DynamicHMC.TreeStatisticsNUTS(-15.394928467596408, 1, turning at positions 0:1, 1.0, 1, DynamicHMC.Directions(0x2289e963)), DynamicHMC.TreeStatisticsNUTS(-16.89394380099118, 2, turning at positions -3:0, 0.8671555284935858, 3, DynamicHMC.Directions(0x814a6c80)), DynamicHMC.TreeStatisticsNUTS(-17.161027698625507, 1, turning at positions -1:0, 0.9703731661510693, 1, DynamicHMC.Directions(0x86ab5f50)), DynamicHMC.TreeStatisticsNUTS(-16.97829873987515, 3, turning at positions -4:3, 0.9997923514806402, 7, DynamicHMC.Directions(0x8e11485b)), DynamicHMC.TreeStatisticsNUTS(-17.89201507618953, 1, turning at positions -1:-2, 0.8903755079376818, 3, DynamicHMC.Directions(0xb3418085))  ‚Ä¶  DynamicHMC.TreeStatisticsNUTS(-16.26604990315287, 1, turning at positions 0:1, 0.959736492481265, 1, DynamicHMC.Directions(0x557600b3)), DynamicHMC.TreeStatisticsNUTS(-16.951341843338955, 2, turning at positions -1:2, 0.9632171118796427, 3, DynamicHMC.Directions(0xe3936c5a)), DynamicHMC.TreeStatisticsNUTS(-16.072221189608445, 2, turning at positions -1:2, 0.9999999999999999, 3, DynamicHMC.Directions(0x949573a2)), DynamicHMC.TreeStatisticsNUTS(-16.55801563458408, 3, turning at positions -6:1, 0.88395283320536, 7, DynamicHMC.Directions(0xf461c7c9)), DynamicHMC.TreeStatisticsNUTS(-15.438600032828676, 2, turning at positions -3:0, 0.9863946673636516, 3, DynamicHMC.Directions(0x2bb08f44)), DynamicHMC.TreeStatisticsNUTS(-15.295092284123097, 1, turning at positions -1:-2, 0.9965912021390985, 3, DynamicHMC.Directions(0xca701ddd)), DynamicHMC.TreeStatisticsNUTS(-15.3116025453622, 3, turning at positions -5:2, 0.9945182275367083, 7, DynamicHMC.Directions(0xc859ff0a)), DynamicHMC.TreeStatisticsNUTS(-15.286728501135572, 1, turning at positions 2:3, 0.9975529664396771, 3, DynamicHMC.Directions(0x4003d5b7)), DynamicHMC.TreeStatisticsNUTS(-15.411914406142788, 2, turning at positions -3:0, 0.9824349057414384, 3, DynamicHMC.Directions(0xc0046d58)), DynamicHMC.TreeStatisticsNUTS(-16.474989454501255, 1, turning at positions 1:2, 0.8791956284578412, 3, DynamicHMC.Directions(0xbe74ca46))], Œ∫ = Gaussian kinetic energy (LinearAlgebra.Diagonal), ‚àödiag(M‚Åª¬π): [0.4094190940850893], œµ = 0.8186130211173526)</code></pre><p>To get the posterior for <span>$Œ±$</span>, we need to use <code>get_position</code> and then transform</p><pre><code class="language-julia">posterior = transform.(t, results.chain);</code></pre><pre><code class="language-none">1000-element Array{NamedTuple{(:Œ±,),Tuple{Float64}},1}:
 (Œ± = 0.4224922289555681,) 
 (Œ± = 0.6105840510233069,) 
 (Œ± = 0.4844044063770361,) 
 (Œ± = 0.42424416858605885,)
 (Œ± = 0.5543071231800618,) 
 (Œ± = 0.5526908980461119,) 
 (Œ± = 0.6805692103894798,) 
 (Œ± = 0.6924240114644543,) 
 (Œ± = 0.6613901804309453,) 
 (Œ± = 0.4661949537213493,) 
 ‚ãÆ                         
 (Œ± = 0.36151477484611416,)
 (Œ± = 0.4603128300116229,) 
 (Œ± = 0.5339491734419402,) 
 (Œ± = 0.5159975095175382,) 
 (Œ± = 0.4887465019120278,) 
 (Œ± = 0.4829299407037817,) 
 (Œ± = 0.5074030328075104,) 
 (Œ± = 0.5366975920098795,) 
 (Œ± = 0.40209956298516153,)</code></pre><p>Extract the parameter.</p><pre><code class="language-julia">posterior_Œ± = first.(posterior);</code></pre><pre><code class="language-none">1000-element Array{Float64,1}:
 0.4224922289555681 
 0.6105840510233069 
 0.4844044063770361 
 0.42424416858605885
 0.5543071231800618 
 0.5526908980461119 
 0.6805692103894798 
 0.6924240114644543 
 0.6613901804309453 
 0.4661949537213493 
 ‚ãÆ                  
 0.36151477484611416
 0.4603128300116229 
 0.5339491734419402 
 0.5159975095175382 
 0.4887465019120278 
 0.4829299407037817 
 0.5074030328075104 
 0.5366975920098795 
 0.40209956298516153</code></pre><p>check the mean</p><pre><code class="language-julia">mean(posterior_Œ±)</code></pre><pre><code class="language-none">0.5007748934712232</code></pre><p>check the effective sample size</p><pre><code class="language-julia">ess_Œ± = effective_sample_size(posterior_Œ±)</code></pre><pre><code class="language-none">396.6953149153662</code></pre><p>NUTS-specific statistics</p><pre><code class="language-julia">summarize_tree_statistics(results.tree_statistics)</code></pre><pre><code class="language-none">Hamiltonian Monte Carlo sample of length 1000
  acceptance rate mean: 0.96, 5/25/50/75/95%: 0.82 0.94 0.98 1.0 1.0
  termination: divergence =&gt; 0%, max_depth =&gt; 0%, turning =&gt; 100%
  depth: 0 =&gt; 0%, 1 =&gt; 50%, 2 =&gt; 27%, 3 =&gt; 23%</code></pre><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Overview</span></a><a class="next" href="../example_linear_regression/"><span class="direction">Next</span><span class="title">Linear regression</span></a></footer></article></body></html>
